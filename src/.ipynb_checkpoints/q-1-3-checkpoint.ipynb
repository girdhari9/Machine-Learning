{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Giridhari Lal Gupta\n",
    "#### Roll Number : 2018201019\n",
    "## Decision Tree\n",
    "##### Decision Tree classifier to predict which valuable employees will leave next . This tree helps in reducing the number of senior employees leaving the company by predicting the next bunch\n",
    "#### Data set downloaded from : http://researchweb.iiit.ac.in/~murtuza.bohra/decision_Tree.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import-Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import scipy.stats as stats\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = {}\n",
    "\n",
    "    def display(self, level = 0):\n",
    "        if self.children == {}: \n",
    "            print(\": \", self.attribute, end=\"\")\n",
    "        else:\n",
    "            for value in self.children.keys():\n",
    "                prefix = \"\\n\" + \" \" * level * 4\n",
    "                print(prefix, self.attribute, \"=\", value, end=\"\")\n",
    "                self.children[value].display(level + 1)\n",
    "     \n",
    "    def predicts(self, root, catAtt):\n",
    "        if self.children == {}: \n",
    "            return self.attribute\n",
    "        if self.attribute in catAtt:\n",
    "            value = root[self.attribute]\n",
    "            if value in self.children:\n",
    "                subtree = self.children[value]\n",
    "                return subtree.predicts(root, catAtt)\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            val = 0\n",
    "            for val1 in self.children.keys():\n",
    "                val = val1\n",
    "            feature_name, comparison_operator, value, pos = val.split(\" \")\n",
    "            if root[feature_name] <= float(value):\n",
    "                Question = \"{} <= {} left\".format(feature_name, value)\n",
    "                subtree = self.children[Question]\n",
    "            else:\n",
    "                Question = \"{} <= {} right\".format(feature_name, value)\n",
    "                subtree = self.children[Question]\n",
    "            \n",
    "            return subtree.predicts(root, catAtt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountTotalLabels(labelData):\n",
    "    positive, negative = 0, 0\n",
    "    for label in labelData:\n",
    "        if label == 0:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misclassification-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MisclassificationRate(examples, target):\n",
    "    positive, negative = CountTotalLabels(examples[target])\n",
    "    Total = positive + negative\n",
    "    positive = positive / Total\n",
    "    negative = negative / Total\n",
    "    MSR = -999\n",
    "    if MSR < positive:\n",
    "        MSR = positive\n",
    "    if MSR < negative:\n",
    "        MSR = negative\n",
    "    return MSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniIndex(examples, target):\n",
    "    positive, negative = CountTotalLabels(examples[target])\n",
    "    Total = positive + negative\n",
    "    positive = positive / Total\n",
    "    negative = negative / Total\n",
    "    giniIndex = positive * positive + negative * negative\n",
    "    return (1 - giniIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(examples, target):\n",
    "    positive, negative = CountTotalLabels(examples[target])\n",
    "    logv = log(2)\n",
    "    logv = logv * (positive + negative)\n",
    "    Entropy = 0.0\n",
    "    if not positive == 0:\n",
    "        Entropy = positive * (-log(positive/(positive + negative)))/logv\n",
    "    if not negative == 0:\n",
    "        Entropy = Entropy + negative * (-log(negative/(positive + negative)))/logv\n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    unique_values = np.unique(data)\n",
    "    potential_splits = []\n",
    "    unique_values.sort()\n",
    "    for index in range(len(unique_values)):\n",
    "        if index != 0:\n",
    "            current_value = unique_values[index]\n",
    "            previous_value = unique_values[index - 1]\n",
    "            potential_split = (current_value + previous_value) / 2\n",
    "            potential_splits.append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get-Best-Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestAttribute(examples, target, attributes, infoFunction, catAtt):\n",
    "    baseEntropy = infoFunction(examples, target)\n",
    "    TotalLength = len(examples)\n",
    "    informationGain = []\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        if attribute in catAtt:\n",
    "            groupedData = examples.groupby(attribute)\n",
    "            totalEntropy = 0\n",
    "            for key,exampleSubset in groupedData:\n",
    "                del exampleSubset[attribute]\n",
    "                entropyOfSubset = infoFunction(exampleSubset,target)\n",
    "                totalEntropy += (len(exampleSubset)/ TotalLength) * entropyOfSubset\n",
    "            informationGain.append([attribute, baseEntropy-totalEntropy, key])\n",
    "        else:\n",
    "            potential_splits = get_potential_splits(examples[attribute])\n",
    "            totalEntropy, val, overall_entropy = 0, 0, 999\n",
    "            for value in potential_splits:\n",
    "                data_below, data_above = split_data(examples, split_column=attribute, split_value=value)\n",
    "                n = len(data_below) + len(data_above)\n",
    "                totalEntropy =  ((len(data_below) / n) * infoFunction(data_below, target) \n",
    "                                  + (len(data_above) / n) * infoFunction(data_above, target))\n",
    "                if totalEntropy <= overall_entropy:\n",
    "                    overall_entropy = totalEntropy\n",
    "                    val = value\n",
    "            informationGain.append([attribute,baseEntropy-overall_entropy,val])\n",
    "\n",
    "    bestAttribute = max(informationGain, key=lambda x: x[1])\n",
    "    return bestAttribute[0], bestAttribute[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(examples, target, attributes):\n",
    "    if len(attributes) == 0:\n",
    "        item_counts = examples[target].value_counts()\n",
    "        max_item = item_counts.idxmax()\n",
    "        return max_item\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_purity(examples, target):\n",
    "    uniques = examples.apply(lambda x: x.nunique()).loc[target]\n",
    "    if uniques == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(examples, target, attributes1, infoFunction, catAtt):\n",
    "    attributes = attributes1[:] # Make it as Local\n",
    "    if data_purity(examples, target):\n",
    "        return TreeNode(examples[target].iloc[0])\n",
    "\n",
    "    max_item = classify_data(examples, target, attributes)\n",
    "    if len(attributes) == 0:\n",
    "        return TreeNode(max_item)\n",
    "    \n",
    "    \n",
    "    bestAttribute, bestValue = getBestAttribute(examples, target, attributes, infoFunction, catAtt)\n",
    "    attributeRoot = TreeNode(bestAttribute)\n",
    "    \n",
    "    if bestAttribute in catAtt:\n",
    "        attributes.remove(bestAttribute)\n",
    "        groupedData = examples.groupby(bestAttribute)\n",
    "        for key,exampleSubset in groupedData:\n",
    "                if len(exampleSubset) == 0:\n",
    "                    item_counts = exampleSubset[target].value_counts()\n",
    "                    max_item = item_counts.idxmax()\n",
    "                    attributeRoot.children[key] = TreeNode(max_item)\n",
    "                else:\n",
    "                    attributeRoot.children[key] = decisionTree(exampleSubset.drop([bestAttribute],axis=1), target, attributes, infoFunction, catAtt)\n",
    "    else:\n",
    "        data_below, data_above = split_data(examples, split_column=bestAttribute, split_value=bestValue)\n",
    "\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            attributes.remove(bestAttribute)\n",
    "            item_counts = examples[target].value_counts()\n",
    "            max_item = item_counts.idxmax()\n",
    "            return TreeNode(max_item) \n",
    "        \n",
    "        key = \"{} <= {} left\".format(bestAttribute, bestValue)\n",
    "    \n",
    "        attributeRoot.children[key] = decisionTree(data_below, target, attributes, infoFunction, catAtt)\n",
    "        key = \"{} <= {} right\".format(bestAttribute, bestValue)\n",
    "\n",
    "        attributeRoot.children[key] = decisionTree(data_above, target, attributes, infoFunction, catAtt)\n",
    "\n",
    "    return attributeRoot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    \n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluatingTree(tree, test, target, catAtt):\n",
    "    correct = 0\n",
    "    TP, FN, FP = 0,0,0\n",
    "    for i in range(0, len(test)):\n",
    "        if str(tree.predicts(test.loc[i], catAtt)) == str(test.loc[i,target]):\n",
    "            correct += 1\n",
    "            if(test.loc[i, target] == 0):\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "        else:\n",
    "            if(test.loc[i, target] == 0):\n",
    "                FN += 1\n",
    "    print(\"\\nThe accuracy is: \", correct/len(test))\n",
    "    X = TP + FN\n",
    "    Y = TP + FP\n",
    "    Recall, Precision = 1, 1\n",
    "    if X:\n",
    "        Recall = TP/ X\n",
    "    if Y:\n",
    "        Precision = TP/ Y\n",
    "    print(\"\\nRecall is : \", Recall)\n",
    "    print(\"\\nPrecision is : \", Precision)\n",
    "    if Precision or Recall:\n",
    "        print(\"\\nF1 Score is : \", (2 * (Recall * Precision))/ (Recall + Precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"../input_data/train.csv\")\n",
    "    \n",
    "    target = \"left\"\n",
    "\n",
    "    train, test = train_test_split(df, test_size = 0.2)\n",
    "    test = test.reset_index()\n",
    "\n",
    "    attributes = train.columns.tolist()\n",
    "    attributes.remove(target)\n",
    "    \n",
    "    catAtt = ['Work_accident', 'promotion_last_5years', 'sales', 'salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Effectiveness of Misclassification rate, Gini, Entropy as impurity measures in terms of precision, recall and accuracy.\n",
    "\n",
    "##### Accuracy  =  ( TP + TN ) / ( TP + FP + TN + FN )\n",
    "\n",
    "##### Precsion  = TP / ( TP + FP )\n",
    "\n",
    "##### Recall  = TP / ( TP + FN )\n",
    "\n",
    "##### F1 = (2  x Precision x) / ( Precision + Recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeEn = decisionTree(train, target, attributes, getEntropy, catAtt)\n",
    "treeGini = decisionTree(train, target, attributes, giniIndex, catAtt)\n",
    "treeMis = decisionTree(train, target, attributes, MisclassificationRate, catAtt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entorpy Measures in terms of Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy is:  0.9719750889679716\n",
      "\n",
      "Recall is :  0.9188712522045855\n",
      "\n",
      "Precision is :  0.23844393592677346\n",
      "\n",
      "F1 Score is :  0.37863372093023256\n"
     ]
    }
   ],
   "source": [
    "EvaluatingTree(treeEn, test, target, catAtt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index Measures in terms of Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy is:  0.9737544483985765\n",
      "\n",
      "Recall is :  0.9284436493738819\n",
      "\n",
      "Precision is :  0.23709456372772955\n",
      "\n",
      "F1 Score is :  0.3777292576419214\n"
     ]
    }
   ],
   "source": [
    "EvaluatingTree(treeGini, test, target, catAtt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclasification Measures in terms of Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy is:  0.9328291814946619\n",
      "\n",
      "Recall is :  0.8757281553398059\n",
      "\n",
      "Precision is :  0.2150691463996185\n",
      "\n",
      "F1 Score is :  0.3453292496171516\n"
     ]
    }
   ],
   "source": [
    "EvaluatingTree(treeMis, test, target, catAtt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
